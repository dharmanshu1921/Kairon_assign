{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5232472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in ./.venv/lib/python3.12/site-packages (2.1.3)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (0.6.17)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.52 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (0.3.56)\n",
      "Requirement already satisfied: pydantic<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (2.11.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.39.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (6.31.0rc1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./.venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.72.0rc1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.72.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.3.37)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.3.1)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: colorama\n",
      "Successfully installed colorama-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bace639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import platform\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import ToolMessage, HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnableConfig, Runnable\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.constants import END, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from pydantic import BaseModel\n",
    "from typing import Annotated, Optional, Literal, List\n",
    "from typing_extensions import TypedDict\n",
    "import colorama\n",
    "colorama.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e46759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"\\033[37m%(asctime)s - %(levelname)s - %(message)s\\033[0m\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a789a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "if not load_dotenv():\n",
    "    logger.error(\"Failed to load .env file. Ensure it exists and is readable.\")\n",
    "    raise ValueError(\"Failed to load .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a81b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "392ee89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dotenv path: '/Users/dharmanshusingh/Desktop/Kairon_assign/.env'\n",
      "GROQ_API_KEY: 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\n",
      "GEMINI_API_KEY: AIzaSyCihdVXQDYWiKO3lvR6rHD2faFkPuBKByg\n",
      "TAVILY_API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Where is .env?\n",
    "dotenv_path = find_dotenv()\n",
    "print(\"Dotenv path:\", repr(dotenv_path))\n",
    "\n",
    "# Load (and override any existing vars)\n",
    "load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "# Show what actually got loaded\n",
    "print(\"GROQ_API_KEY:\", os.getenv(\"GROQ_API_KEY\"))\n",
    "print(\"GEMINI_API_KEY:\", os.getenv(\"GEMINI_API_KEY\"))\n",
    "print(\"TAVILY_API_KEY:\", os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fcc9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate API keys\n",
    "if not GEMINI_API_KEY:\n",
    "    logger.error(\"GEMINI_API_KEY is not set.\")\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set in the .env file.\")\n",
    "if not TAVILY_API_KEY:\n",
    "    logger.error(\"TAVILY_API_KEY is not set.\")\n",
    "    raise ValueError(\"TAVILY_API_KEY is not set in the .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89a8c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print events\n",
    "def _print_event(event: dict, _printed: set, max_length: int = 1500) -> None:\n",
    "    current_state = event.get(\"dialog_state\", \"None\")\n",
    "    logger.info(f\"Current state: {current_state}\")\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=False)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            logger.info(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e2c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templates\n",
    "research_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"\n",
    "You are an expert research agent. Your task is to deeply research the user's query using the Tavily search tool. Gather accurate, current, and relevant data. If no relevant results are found, indicate this clearly and suggest alternative approaches. Avoid speculation and focus on precision and reliability.\n",
    "        \"\"\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "draft_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"\n",
    "You are a professional drafting agent. Your task is to take the research agent's response and rephrase it into a polished, professional format suitable for a formal report or presentation. Follow these guidelines:\n",
    "- Use a formal tone, avoiding colloquial or informal language.\n",
    "- Structure the response with clear headings, bullet points, or paragraphs as appropriate.\n",
    "- Retain all key details (e.g., names, dates, technologies) but make the content concise and well-organized.\n",
    "- Eliminate redundancy and ensure clarity for a professional audience.\n",
    "- If the input lacks sufficient detail, note this professionally and suggest further research.\n",
    "        \"\"\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d3e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "def initialize_llm() -> ChatGoogleGenerativeAI:\n",
    "    try:\n",
    "        return ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", api_key=GEMINI_API_KEY, temperature=0.7)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize LLM: {e}\")\n",
    "        raise ValueError(f\"Failed to initialize LLM: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73dcb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tools\n",
    "def initialize_tools() -> List[TavilySearchResults]:\n",
    "    try:\n",
    "        return [TavilySearchResults(max_results=5, api_key=TAVILY_API_KEY)]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize Tavily search tool: {e}\")\n",
    "        raise ValueError(f\"Failed to initialize Tavily search tool: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08b423d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State definition\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    dialog_state: Literal[\"Research Agent\", \"Draft Agent\", None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d65e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant agent class\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable, node_name: str):\n",
    "        self.runnable = runnable\n",
    "        self.node_name = node_name  # Track the node name (e.g., \"Research Agent\", \"Draft Agent\")\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig) -> dict:\n",
    "        result = None\n",
    "        max_retries = 3\n",
    "        for _ in range(max_retries):\n",
    "            try:\n",
    "                result = self.runnable.invoke(state)\n",
    "                if not result.content and not hasattr(result, \"tool_calls\"):\n",
    "                    state[\"messages\"].append(HumanMessage(content=\"Please provide a meaningful response.\"))\n",
    "                else:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in {self.node_name}: {e}\")\n",
    "                error_message = AIMessage(content=f\"Error: {str(e)}. Please retry or rephrase your query.\")\n",
    "                return {\"messages\": [error_message], \"dialog_state\": self.node_name}\n",
    "        if not result:\n",
    "            logger.error(f\"{self.node_name} failed to produce a valid response after retries.\")\n",
    "            return {\"messages\": [AIMessage(content=\"Failed to process request.\")], \"dialog_state\": self.node_name}\n",
    "        return {\"messages\": [result], \"dialog_state\": self.node_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ac2ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle tool errors\n",
    "def handle_tool_error(state: dict) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    logger.error(f\"Tool error: {error}\")\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\nPlease try a different query or check the tool configuration.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            ) for tc in tool_calls\n",
    "        ],\n",
    "        \"dialog_state\": \"Research Tools\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa6ef730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tool node with fallback\n",
    "def create_tool_node_with_fallback(tools: list) -> ToolNode:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff72d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing logic from Research Agent\n",
    "def route_from_research_agent(state: State) -> str:\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
    "        logger.info(\"Routing to Research Tools due to tool calls.\")\n",
    "        return \"Research Tools\"\n",
    "    logger.info(\"Routing to Draft Agent.\")\n",
    "    return \"Draft Agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e663e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile LangGraph\n",
    "def build_graph() -> StateGraph:\n",
    "    llm = initialize_llm()\n",
    "    tools_search = initialize_tools()\n",
    "    search_runnable = research_prompt | llm.bind_tools(tools_search)\n",
    "    draft_runnable = draft_prompt | llm  # No tools for draft agent\n",
    "\n",
    "    builder = StateGraph(State)\n",
    "    builder.add_node(\"Research Agent\", Assistant(search_runnable, \"Research Agent\"))\n",
    "    builder.add_node(\"Draft Agent\", Assistant(draft_runnable, \"Draft Agent\"))\n",
    "    builder.add_node(\"Research Tools\", create_tool_node_with_fallback(tools_search))\n",
    "\n",
    "    builder.add_edge(START, \"Research Agent\")\n",
    "    builder.add_conditional_edges(\"Research Agent\", route_from_research_agent, [\"Research Tools\", \"Draft Agent\"])\n",
    "    builder.add_edge(\"Research Tools\", \"Research Agent\")\n",
    "    builder.add_edge(\"Draft Agent\", END)\n",
    "\n",
    "    memory = MemorySaver()\n",
    "    return builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd90b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate graph visualization\n",
    "def generate_graph_visualization(graph: StateGraph) -> None:\n",
    "    try:\n",
    "        graph_image = graph.get_graph(xray=True).draw_mermaid_png()\n",
    "        image_path = \"workflow_graph.png\"\n",
    "        with open(image_path, \"wb\") as f:\n",
    "            f.write(graph_image)\n",
    "        logger.info(f\"Graph saved as {image_path}\")\n",
    "        system = platform.system()\n",
    "        if system == \"Darwin\":\n",
    "            os.system(f\"open {image_path}\")\n",
    "        elif system == \"Windows\":\n",
    "            os.startfile(image_path)\n",
    "        else:\n",
    "            os.system(f\"xdg-open {image_path}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not generate graph visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d8a5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream output updates\n",
    "def run_graph(user_input: str, graph: StateGraph, config: dict) -> None:\n",
    "    _printed = set()\n",
    "    try:\n",
    "        events = graph.stream(\n",
    "            {\"messages\": [HumanMessage(content=user_input)], \"dialog_state\": None},\n",
    "            config=config,\n",
    "            stream_mode=\"values\"\n",
    "        )\n",
    "        for event in events:\n",
    "            _print_event(event, _printed)\n",
    "        # Log final state after streaming\n",
    "        final_state = event.get(\"dialog_state\", \"None\")\n",
    "        logger.info(f\"Workflow completed. Final state: {final_state}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during graph execution: {e}\")\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86e7b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    print(\"Deep Research AI Agentic System is running. Type 'exit' to quit.\")\n",
    "    graph = build_graph()\n",
    "    thread_id = str(uuid.uuid4())\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    # Generate graph visualization\n",
    "    generate_graph_visualization(graph)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        if not user_input.strip() or len(user_input) > 1000:\n",
    "            print(\"Please enter a valid query (non-empty and less than 1000 characters).\")\n",
    "            continue\n",
    "        run_graph(user_input, graph, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec06e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Research AI Agentic System is running. Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 19:57:34,046 - INFO - Graph saved as workflow_graph.png\n",
      "2025-04-26 19:57:48,489 - INFO - Current state: None\n",
      "2025-04-26 19:57:48,494 - INFO - ================================ Human Message =================================\n",
      "\n",
      "latest news about nvidia\n",
      "2025-04-26 19:57:50,943 - INFO - Routing to Research Tools due to tool calls.\n",
      "2025-04-26 19:57:50,947 - INFO - Current state: Research Agent\n",
      "2025-04-26 19:57:50,948 - INFO - ================================== Ai Message ==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (cad740a7-99db-445e-b117-079346100390)\n",
      " Call ID: cad740a7-99db-445e-b117-079346100390\n",
      "  Args:\n",
      "    query: latest news about nvidia\n",
      "2025-04-26 19:57:54,322 - INFO - Current state: Research Agent\n",
      "2025-04-26 19:57:54,325 - INFO - ================================= Tool Message =================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Latest News - NVIDIA Newsroom\", \"url\": \"https://nvidianews.nvidia.com/news/latest?c=21926\", \"content\": \"NVIDIA Blackwell Ultra DGX SuperPOD Delivers Out-of-the-Box AI Supercomputer for Enterprises to Build AI Factories\\n\\nNVIDIA Announces Major Release of Cosmos World Foundation Models and Physical AI Data Tools\\n\\nNVIDIA Launches Family of Open Reasoning AI Models for Developers and Enterprises to Build Agentic AI Platforms\\n\\nNVIDIA Announces Isaac GR00T N1 — the World’s First Open Humanoid Robot Foundation Model — and Simulation Frameworks to Speed Robot Development [...] Latest News\\n\\nNVIDIA Blackwell GeForce RTX Arrives for Every Gamer, Starting at $299\\n\\nOracle and NVIDIA Collaborate to Help Enterprises Accelerate Agentic AI Inference\\n\\nNVIDIA to Build Accelerated Quantum Computing Research Center\\n\\nNVIDIA and GE HealthCare Collaborate to Advance the Development of Autonomous Diagnostic Imaging With Physical AI\\n\\nNVIDIA, Alphabet and Google Collaborate on the Future of Agentic and Physical AI [...] NVIDIA Blackwell RTX PRO Comes to Workstations and Servers for Designers, Developers, Data Scientists and Creatives to Build and Collaborate With Agentic AI\\n\\nNVIDIA Announces DGX Spark and DGX Station Personal AI Computers\\n\\nNVIDIA Announces Spectrum-X Photonics, Co-Packaged Optics Networking Switches to Scale AI Factories to Millions of GPUs\\ ... (truncated)\n",
      "2025-04-26 19:57:55,959 - INFO - Routing to Draft Agent.\n",
      "2025-04-26 19:57:55,962 - INFO - Current state: Research Agent\n",
      "2025-04-26 19:57:55,964 - INFO - ================================== Ai Message ==================================\n",
      "\n",
      "Based on the search results from Tavily, here's a summary of the latest news about NVIDIA:\n",
      "\n",
      "Several news sources report on recent NVIDIA announcements, including new products like the Blackwell Ultra DGX SuperPOD,  Blackwell GeForce RTX, and the Isaac GR00T N1 humanoid robot foundation model.  There are also announcements of collaborations with companies like Oracle and GE Healthcare on AI projects.  Other news items cover various aspects of NVIDIA's involvement in AI research and development, such as work on generative AI and agentic AI.  Finally, some articles discuss the impact of US export restrictions on NVIDIA's business in China.  The articles span a range of topics including new product launches, partnerships, AI advancements and financial impacts.\n",
      "2025-04-26 19:57:56,952 - INFO - Current state: Draft Agent\n",
      "2025-04-26 19:57:56,954 - INFO - ================================== Ai Message ==================================\n",
      "\n",
      "**Note:**  The provided data lacks specific dates for most announcements.  Further research is recommended to add precise dates and details for each news item mentioned above to create a more comprehensive and accurate report.  Furthermore, a critical analysis of the various sources and their potential biases would enhance the report's objectivity.\n",
      "2025-04-26 19:57:56,955 - INFO - Workflow completed. Final state: Draft Agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0f538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
